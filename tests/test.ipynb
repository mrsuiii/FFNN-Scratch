{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: Training Loss = 0.8987747508968625, Validation Loss = 0.4266734977703012\n",
      "Epoch 2/20: Training Loss = 0.3740118362903595, Validation Loss = 0.33387718526085475\n",
      "Epoch 3/20: Training Loss = 0.31196106673989976, Validation Loss = 0.2967215373496829\n",
      "Epoch 4/20: Training Loss = 0.27868279199940815, Validation Loss = 0.27325744981736777\n",
      "Epoch 5/20: Training Loss = 0.2550456403706755, Validation Loss = 0.2554862572906412\n",
      "Epoch 6/20: Training Loss = 0.2362235957639558, Validation Loss = 0.24058312241728325\n",
      "Epoch 7/20: Training Loss = 0.22002168367164476, Validation Loss = 0.22747242703509446\n",
      "Epoch 8/20: Training Loss = 0.2055683751659734, Validation Loss = 0.21551998712120382\n",
      "Epoch 9/20: Training Loss = 0.19255307136688912, Validation Loss = 0.20500062173841316\n",
      "Epoch 10/20: Training Loss = 0.180816958039999, Validation Loss = 0.19555567375986585\n",
      "Epoch 11/20: Training Loss = 0.17021276038459368, Validation Loss = 0.1871069629045639\n",
      "Epoch 12/20: Training Loss = 0.16059105796473366, Validation Loss = 0.17958199902368102\n",
      "Epoch 13/20: Training Loss = 0.15181865837744304, Validation Loss = 0.17287614046140543\n",
      "Epoch 14/20: Training Loss = 0.14391197608624187, Validation Loss = 0.16694576363693425\n",
      "Epoch 15/20: Training Loss = 0.1367440368171249, Validation Loss = 0.161530031307447\n",
      "Epoch 16/20: Training Loss = 0.13021147755214146, Validation Loss = 0.15660176669249834\n",
      "Epoch 17/20: Training Loss = 0.12425367316816534, Validation Loss = 0.15211633265600064\n",
      "Epoch 18/20: Training Loss = 0.11883000893039362, Validation Loss = 0.14809979530499465\n",
      "Epoch 19/20: Training Loss = 0.11381674592729125, Validation Loss = 0.14445101144411518\n",
      "Epoch 20/20: Training Loss = 0.10918003301748208, Validation Loss = 0.14113998066556044\n",
      "Training Loss History: [0.8987747508968625, 0.3740118362903595, 0.31196106673989976, 0.27868279199940815, 0.2550456403706755, 0.2362235957639558, 0.22002168367164476, 0.2055683751659734, 0.19255307136688912, 0.180816958039999, 0.17021276038459368, 0.16059105796473366, 0.15181865837744304, 0.14391197608624187, 0.1367440368171249, 0.13021147755214146, 0.12425367316816534, 0.11883000893039362, 0.11381674592729125, 0.10918003301748208]\n",
      "Validation Loss History: [0.4266734977703012, 0.33387718526085475, 0.2967215373496829, 0.27325744981736777, 0.2554862572906412, 0.24058312241728325, 0.22747242703509446, 0.21551998712120382, 0.20500062173841316, 0.19555567375986585, 0.1871069629045639, 0.17958199902368102, 0.17287614046140543, 0.16694576363693425, 0.161530031307447, 0.15660176669249834, 0.15211633265600064, 0.14809979530499465, 0.14445101144411518, 0.14113998066556044]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.Value import Value, draw_dot\n",
    "from src.activation import * \n",
    "from src.init import he_init\n",
    "from src.Layer import Layer\n",
    "from src.FFNN import FFNN\n",
    "from src.loss import cce_loss  \n",
    "from sklearn.metrics import accuracy_score\n",
    "def one_hot_encode(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Konversi array label ke one-hot encoding.\n",
    "    y: array dengan shape (n_samples, 1) atau (n_samples,)\n",
    "    \"\"\"\n",
    "    y = y.flatten().astype(int)\n",
    "    one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    one_hot[np.arange(y.shape[0]), y] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Muat dataset MNIST dari OpenML\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "# Normalisasi fitur ke rentang [0,1]\n",
    "X = X.astype(np.float32) / 255.0\n",
    "\n",
    "# Konversi label ke integer\n",
    "y = y.astype(np.int32)\n",
    "\n",
    "# Ubah label ke one-hot encoding untuk 10 kelas\n",
    "y_onehot = one_hot_encode(y, num_classes=10)\n",
    "\n",
    "# Bagi data menjadi training dan validation (misal 80% training, 20% validasi)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Bungkus data menggunakan class Value\n",
    "X_train = Value(X_train)\n",
    "y_train = Value(y_train)\n",
    "X_val = Value(X_val)\n",
    "y_val = Value(y_val)\n",
    "\n",
    "# Definisikan arsitektur model.\n",
    "# Karena MNIST memiliki 784 fitur, layer pertama menggunakan 784 neuron.\n",
    "# Output layer memiliki 10 neuron dengan fungsi aktivasi softmax.\n",
    "layers = [\n",
    "    Layer(784, 128, activation=relu, weight_init=he_init),\n",
    "    Layer(128, 32, activation= relu, weight_init=he_init),\n",
    "    Layer(32, 10, activation=softmax, weight_init=he_init)\n",
    "]\n",
    "\n",
    "# Buat instance model FFNN dengan loss function cce_loss\n",
    "model = FFNN(layers=layers, loss_fn=cce_loss, lr=0.01)\n",
    "\n",
    "# Latih model dengan parameter batch_size, max_epoch, dan error_threshold yang diinginkan\n",
    "training_history = model.train(\n",
    "    training_data=X_train,\n",
    "    training_target=y_train,\n",
    "    max_epoch=20,            # jumlah epoch maksimum\n",
    "    error_threshold=0.01,    # ambang error untuk penghentian training\n",
    "    batch_size=64,           # ukuran mini-batch\n",
    "    validation_data=X_val,   # data validasi (opsional)\n",
    "    validation_target=y_val, # target validasi (opsional)\n",
    "    verbose=True             # tampilkan progress training\n",
    ")\n",
    "\n",
    "print(\"Training Loss History:\", training_history['training_loss_history'])\n",
    "print(\"Validation Loss History:\", training_history['validation_loss_history'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X_val)\n",
    "pred = np.argmax(pred.data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.93%\n"
     ]
    }
   ],
   "source": [
    "def decode(y_onehot):\n",
    "    return np.argmax(y_onehot, axis=1)\n",
    "y_val = decode(y_val.data)\n",
    "accuracy = accuracy_score(y_val, pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
